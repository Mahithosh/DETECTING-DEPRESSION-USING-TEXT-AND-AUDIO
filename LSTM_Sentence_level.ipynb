{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_Sentence_level.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMPIeGfI7kf2mT8ahk2Y01G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vKUFgm_UNP7e","executionInfo":{"status":"ok","timestamp":1627106513078,"user_tz":-330,"elapsed":1353,"user":{"displayName":"Sri Vishnuvardhan Reddy Akepati","photoUrl":"","userId":"12972633878670662839"}},"outputId":"eebcf5ba-ff93-4900-c9c2-6d1dcba9b246"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lgbj10mpOkix","executionInfo":{"status":"ok","timestamp":1627106514980,"user_tz":-330,"elapsed":21,"user":{"displayName":"Sri Vishnuvardhan Reddy Akepati","photoUrl":"","userId":"12972633878670662839"}},"outputId":"bc90ecff-81e4-4c1a-d664-933c7002b3a1"},"source":["import gc\n","import nltk\n","nltk.download('stopwords')\n","import math\n","\n","from smart_open import open\n","from nltk.corpus import stopwords\n","import sklearn\n","from sklearn.metrics import classification_report\n","from keras.layers import Dropout\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from gensim.models.keyedvectors import KeyedVectors\n","\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","\n","from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n","from tensorflow.keras import layers\n","\n","\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import concatenate"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WRr1QzBPOzkF","executionInfo":{"status":"ok","timestamp":1627106514982,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sri Vishnuvardhan Reddy Akepati","photoUrl":"","userId":"12972633878670662839"}}},"source":["#Text\n","class Highway(layers.Layer):\n","\n","  def __init__(self):\n","    super(Highway, self).__init__()\n","\n","  def build(self, input_shape):\n","    n_sentences = input_shape[1]\n","    n_features = input_shape[2]\n","    carry_bias = keras.initializers.Constant(value=-1.0)\n","    random_dist = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n","\n","    carry_bias_2 = keras.initializers.Constant(value= 0.1)\n","\n","    self.W_T = self.add_weight(shape=(n_features, n_features),initializer = random_dist,trainable=True)\n","    self.b_T = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias, trainable=True)\n","   \n","    self.W = self.add_weight(shape=( n_features, n_features),initializer = random_dist, trainable=True)\n","    self.b = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias_2, trainable=True) \n","\n","\n","  def call(self, inputs):\n","    x = inputs\n","    T = tf.sigmoid(tf.matmul(x, self.W_T) + self.b_T, name=\"transform_gate\")\n","    H = tf.nn.relu(tf.matmul(x, self.W) + self.b, name=\"activation\")\n","    C = tf.subtract(1.0, T, name=\"carry_gate\")\n","    \n","    return tf.add(tf.multiply(H, T), tf.multiply(x, C), \"y\")    \n"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"gyPN2Dy9xORZ","executionInfo":{"status":"ok","timestamp":1627106514984,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sri Vishnuvardhan Reddy Akepati","photoUrl":"","userId":"12972633878670662839"}}},"source":[""],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"DB3ZM6HORT5i","executionInfo":{"status":"ok","timestamp":1627106514985,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sri Vishnuvardhan Reddy Akepati","photoUrl":"","userId":"12972633878670662839"}}},"source":["#Audio\n","\n","class Highway(layers.Layer):\n","\n","  def __init__(self):\n","    super(Highway, self).__init__()\n","\n","  def build(self, input_shape):\n","    n_sentences = input_shape[1]\n","    n_features = input_shape[2]\n","    carry_bias = keras.initializers.Constant(value=-1.0)\n","    random_dist = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n","\n","    carry_bias_2 = keras.initializers.Constant(value= 0.1)\n","\n","    self.W_T = self.add_weight(shape=(n_features, n_features),initializer = random_dist,trainable=True)\n","    self.b_T = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias, trainable=True)\n","    # self.W_T = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1),trainable=True)\n","    # self.b_T = tf.Variable(tf.constant(-1.0, shape=[n_data_points, n_sentences, n_features]),trainable=True)\n","   \n","    self.W = self.add_weight(shape=( n_features, n_features),initializer = random_dist, trainable=True)\n","    self.b = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias_2, trainable=True)\n","    # self.W = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1), trainable=True)\n","    # self.b = tf.Variable(tf.constant(0.1, shape=[n_data_points, n_sentences, n_features]), trainable=True)  \n","\n","\n","  def call(self, inputs):\n","    x = inputs\n","    T = tf.sigmoid(tf.matmul(x, self.W_T) + self.b_T, name=\"transform_gate\")\n","    H = tf.nn.relu(tf.matmul(x, self.W) + self.b, name=\"activation\")\n","    C = tf.subtract(1.0, T, name=\"carry_gate\")\n","    \n","    return tf.add(tf.multiply(H, T), tf.multiply(x, C), \"y\")\n","#Audio\n","\n","class Highway(layers.Layer):\n","\n","  def __init__(self):\n","    super(Highway, self).__init__()\n","\n","  def build(self, input_shape):\n","    n_sentences = input_shape[1]\n","    n_features = input_shape[2]\n","    carry_bias = keras.initializers.Constant(value=-1.0)\n","    random_dist = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n","\n","    carry_bias_2 = keras.initializers.Constant(value= 0.1)\n","\n","    self.W_T = self.add_weight(shape=(n_features, n_features),initializer = random_dist,trainable=True)\n","    self.b_T = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias, trainable=True)\n","    # self.W_T = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1),trainable=True)\n","    # self.b_T = tf.Variable(tf.constant(-1.0, shape=[n_data_points, n_sentences, n_features]),trainable=True)\n","   \n","    self.W = self.add_weight(shape=( n_features, n_features),initializer = random_dist, trainable=True)\n","    self.b = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias_2, trainable=True)\n","    # self.W = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1), trainable=True)\n","    # self.b = tf.Variable(tf.constant(0.1, shape=[n_data_points, n_sentences, n_features]), trainable=True)  \n","\n","\n","  def call(self, inputs):\n","    x = inputs\n","    T = tf.sigmoid(tf.matmul(x, self.W_T) + self.b_T, name=\"transform_gate\")\n","    H = tf.nn.relu(tf.matmul(x, self.W) + self.b, name=\"activation\")\n","    C = tf.subtract(1.0, T, name=\"carry_gate\")\n","    \n","    return tf.add(tf.multiply(H, T), tf.multiply(x, C), \"y\")\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"-uO61OgKR3vS","executionInfo":{"status":"ok","timestamp":1627106514987,"user_tz":-330,"elapsed":20,"user":{"displayName":"Sri Vishnuvardhan Reddy Akepati","photoUrl":"","userId":"12972633878670662839"}}},"source":["#Text + Audio \n","class Highway(layers.Layer):\n","\n","  def __init__(self):\n","    super(Highway, self).__init__()\n","\n","  def build(self, input_shape):\n","    n_sentences = input_shape[1]\n","    n_features = input_shape[2]\n","    carry_bias = keras.initializers.Constant(value=-1.0)\n","    random_dist = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n","\n","    carry_bias_2 = keras.initializers.Constant(value= 0.1)\n","\n","    self.W_T = self.add_weight(shape=(n_features, n_features),initializer = random_dist,trainable=True)\n","    self.b_T = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias, trainable=True)\n","    # self.W_T = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1),trainable=True)\n","    # self.b_T = tf.Variable(tf.constant(-1.0, shape=[n_data_points, n_sentences, n_features]),trainable=True)\n","   \n","    self.W = self.add_weight(shape=( n_features, n_features),initializer = random_dist, trainable=True)\n","    self.b = self.add_weight(shape=( n_sentences, n_features),initializer = carry_bias_2, trainable=True)\n","    # self.W = tf.Variable(tf.random.truncated_normal([n_data_points,n_features, n_features], stddev=0.1), trainable=True)\n","    # self.b = tf.Variable(tf.constant(0.1, shape=[n_data_points, n_sentences, n_features]), trainable=True)  \n","\n","\n","  def call(self, inputs):\n","    x = inputs\n","    T = tf.sigmoid(tf.matmul(x, self.W_T) + self.b_T, name=\"transform_gate\")\n","    H = tf.nn.relu(tf.matmul(x, self.W) + self.b, name=\"activation\")\n","    C = tf.subtract(1.0, T, name=\"carry_gate\")\n","    \n","    return tf.add(tf.multiply(H, T), tf.multiply(x, C), \"y\")\n","\n","class text_audio:\n","# first input model\n","  input1 = Input(shape=(250,74), name = 'Audio_input')\n","  # highway6 = Highway()(highway5)\n","  dense1 = Dense(74)(input1)\n","\n","  input3 = Input(shape = (250,5100), name = 'Text_input')\n","  dense4 = Dense(1000)(input3)\n","  dense5 = Dense(500)(dense4)\n","  dense6 = Dense(250)(dense5)\n","  dense3 = Dense(74)(dense6)\n","  # merge input models\n","  merge = concatenate([dense1,dense3], axis = 1)\n","  # interpretation model\n","  lstm = LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)(merge)\n","  output = Dense(1, activation='sigmoid')(lstm)\n","  model = Model(inputs=[input1, input3], outputs=output)\n","  # summarize layers\n","  # print(model.summary())\n","  # # plot graph\n","  # plot_model(model)\n","  optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001)\n","\n","  def run_model(self):\n","    self.model.compile(optimizer=self.optimizer, loss='binary_crossentropy')\n","    return self.model    "],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zYeLz4PtSPwh","executionInfo":{"status":"ok","timestamp":1627106784906,"user_tz":-330,"elapsed":204279,"user":{"displayName":"Sri Vishnuvardhan Reddy Akepati","photoUrl":"","userId":"12972633878670662839"}},"outputId":"2b73c391-0b07-4f4b-aea7-64db34c8b5e0"},"source":["#MAKE DATASET \n","\n","\n","dev_location = \"dev_data\"\n","test_location = \"test_data\"\n","train_location = \"train_data\"\n","\n","devData = np.array(pd.read_csv('/content/drive/My Drive/Dataset/dev_split_Depression_AVEC2017.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n","testData = np.array(pd.read_csv('/content/drive/My Drive/Dataset/full_test_split.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n","trainData = np.array(pd.read_csv('/content/drive/My Drive/Dataset/train_split_Depression_AVEC2017.csv',delimiter=',',encoding='utf-8'))[:, 0:2]\n","\n","\n","dataset = np.concatenate((devData, np.concatenate((testData, trainData))))\n","\n","gc.collect()      \n","max_num_words = 17\n","model = KeyedVectors.load_word2vec_format('/content/drive/My Drive/Dataset/GoogleNews-vectors-negative300.bin.gz', binary=True)\n","stop_words = set(stopwords.words('english'))\n","\n","\n","\n","def checkDataPointExistence(patientID, split):\n","  for i in split:\n","    if(patientID == i[0]):\n","      return True\n","  return False\n","def getData(patientID, location):\n","  # print(\"PatientID: \" + str(int(patientID)))\n","  retData = [int(patientID)]\n","  textD = getTextData(patientID, location)\n","  audioD = getAudioData(patientID, location, textD)\n","  # patientD = np.concatenate((textD, audioD), axis = 1)\n","  # print(\"Final Patient Data: \" + str(patientD.shape))\n","  return textD,audioD\n","\n","def getTextData(patientID, location):\n","  fileName = \"/content/drive/My Drive/Dataset/\"+ str(location) + \"/\" + str(int(patientID)) + \"_TRANSCRIPT.csv\"\n","  file = np.array(pd.read_csv(fileName,delimiter='\\t',encoding='utf-8', engine='python'))\n","\n","  # Remove All Utterences By Ellie:\n","  for i in range(len(file)):\n","    if(file[i][2] != 'Participant'):\n","      np.delete(file, i)\n","      i-=1\n","\n","  # Remove Speaker Columnn\n","  file = np.delete(file, 2, 1)\n","  \n","  # Convert Text Into Word Vectors:\n","  w2vs = np.zeros((1, max_num_words*300))\n","  for i in range(len(file)):\n","    sentence = file[i][2]\n","    w2v = returnWordToVec(sentence)\n","    w2vs = np.concatenate((w2vs, w2v), axis = 0)\n","  w2vs = np.delete(w2vs, 0, 0)  \n","\n","  # Delete Sentences and Replace With W2Vs\n","  file = np.delete(file, 2, 1)\n","  file = np.concatenate((file, w2vs), axis = 1)\n","  return file\n","def remove_StopWords(sentence):\n","    filtered_sentence = [] \n","    for w in sentence: \n","        if w not in stop_words: \n","            filtered_sentence.append(w)\n","    return filtered_sentence\n","\n","def returnWordToVec(sentence):\n","  global max_num_words, stop_words, model\n","  sentence = str(sentence).split(\" \")\n","  sentence = remove_StopWords(sentence)\n","  index_word = 0\n","  wordMatrix = np.zeros(max_num_words*300)\n","  for j in range(min(max_num_words, len(sentence))):\n","    try:\n","      word = sentence[j]\n","      if(word[0] == '<'):\n","        if(word.find('>')!=-1):\n","          word = word[1:-1]\n","        else:\n","          word = word[1:]\n","      else:\n","        if(word.find('>')!=-1):\n","          word = word[0:-1]\n","      ss = np.array(model[word])\n","      wordMatrix[index_word*300:(index_word+1)*300] = ss\n","      index_word+=1\n","    except Exception as e:\n","      continue\n","  wordMatrix = np.array(wordMatrix.reshape(1,-1))\n","  return wordMatrix\n","def audioDataHelper(X):\n","    for i in range(X.shape[0]):\n","        if(X[i,1] == 0):\n","            X[i,0] = 0\n","            for j in range(7):\n","                X[i,j+1] = 0\n","    X = np.array(X)\n","    return X\n","    \n","def getAudioData(patientID, location, textD):\n","  fileName = \"/content/drive/My Drive/Dataset/\"+ str(location) + \"/\" + str(int(patientID)) + \"_COVAREP.csv\"\n","  data = pd.read_csv(fileName,header = None)\n","  data = data.iloc[:,:].values\n","  data = audioDataHelper(data)\n","  # print(\"Audio Raw Data:\" + str(data.shape))\n","  sentenceDatas = []\n","  for sentence in textD:\n","    sentenceStartime = sentence[0]\n","    sentenceEndTime = sentence[1]\n","    startIndex = math.floor(sentenceStartime/0.01)\n","    endIndex = math.ceil(sentenceEndTime/0.01)\n","    # print(\"Start Time: \" + str(startIndex))\n","    # print(\"End Time: \" + str(endIndex))\n","    sentenceData = data[startIndex: endIndex]\n","    sentenceData = np.average(sentenceData, axis = 0)\n","    # This might be a possible error\n","    sentenceData = np.array(sentenceData.reshape(1, -1))\n","    sentenceDatas.append(sentenceData)\n","  \n","  sentenceDatas = np.array(sentenceDatas)\n","  sentenceDatas = np.reshape(sentenceDatas, (textD.shape[0],-1))\n","  # print(\"Audio Final Data:\" + str(sentenceDatas.shape))\n","\n","  return sentenceDatas\n","# Xtrain = []\n","Ytrain = []\n","# Xtest = []\n","Ytest = []\n","\n","\n","audio_train = []\n","text_train = []\n","\n","audio_test = []\n","text_test = []\n","\n","\n","for datapoint in dataset:\n","  # print(datapoint[0])\n","  if(checkDataPointExistence(datapoint[0], devData)):\n","\n","    # Data Point in Dev Set\n","    text,audio = getData(datapoint[0], dev_location)\n","    audio_train.append(audio)\n","    text_train.append(text)\n","    # Xtest.append(data)\n","    Ytrain.append(datapoint[1])\n","    # print(data)\n","  elif(checkDataPointExistence(datapoint[0], testData)):\n","    # Data Point in Test Set\n","    text,audio = getData(datapoint[0], test_location)\n","    audio_test.append(audio)\n","    text_test.append(text)\n","    # Xtest.append(data)\n","    Ytest.append(datapoint[1])\n","  elif(checkDataPointExistence(datapoint[0], trainData)):\n","    # Data Point in Train Set\n","    text,audio = getData(datapoint[0], train_location)\n","    audio_train.append(audio)\n","    text_train.append(text)\n","    # Xtest.append(data)\n","    Ytrain.append(datapoint[1])\n","\n","def refactor(arr, size):\n","  arrsize = arr.shape[0]\n","  temp = np.zeros((size, arr.shape[1]))\n","  for i in range(min(len(arr), size)):\n","    temp[i] = arr[i]\n","  return temp\n","numberOfSentences = 250\n","\n","devData = []\n","trainData = []\n","testData = []\n","gc.collect()\n","\n","for i in range(len(audio_train)):\n","  audio_train[i] = refactor(audio_train[i], numberOfSentences)\n","  text_train[i] = refactor(text_train[i], numberOfSentences)\n","  # print(Xtrain[i].shape)\n","\n","# for i in range(len(audio_dev)):\n","#   audio_dev[i] = refactor(audio_dev[i], numberOfSentences)\n","#   text_dev[i] = refactor(text_dev[i], numberOfSentences)\n","#   # print(Xtrain[i].shape)\n","\n","for i in range(len(audio_test)):\n","  audio_test[i] = refactor(audio_train[i], numberOfSentences)\n","  text_test[i] = refactor(text_train[i], numberOfSentences)\n","  # print(Xtest[i].shape)\n","audio_test = np.array(audio_test)\n","text_test = np.array(text_test)\n","text_test = text_test[:,:,2:]\n","\n","audio_train = np.array(audio_train)\n","text_train = np.array(text_train)\n","text_train = text_train[:,:,2:]\n","\n","# audio_dev = np.array(audio_dev)\n","# text_dev = np.array(text_dev)\n","# text_dev = text_dev[:,:,2:]\n","\n","dataset = []\n","gc.collect()\n","\n","print(audio_test.shape,text_test.shape)\n","print(audio_train.shape,text_train.shape)\n","# print(audio_dev.shape,video_dev.shape,text_dev.shape)\n","\n","Ytrain = np.array(Ytrain)\n","Ytest = np.array(Ytest)\n","\n","\n","import sklearn\n","from sklearn import preprocessing\n","\n","def upsample(X_train,Y_train):\n","  X_train_0 = X_train[Y_train==0]\n","  X_train_1 = X_train[Y_train==1]\n","\n","  Y_train_1 = Y_train[Y_train==1]\n","  # print(Y_train_1.shape)\n","  # print(X_train_1.shape)\n","  size = X_train_0.shape[0] - X_train_1.shape[0]\n","  X = []\n","  Y = []\n","  X_train = list(X_train)\n","  Y_train = list(Y_train)\n","  while(size>0):\n","    size -= 1\n","    index = np.random.randint(0,X_train_1.shape[0]-1)\n","    leave_index = np.random.randint(0,len(X_train)-1)\n","    X_add = X_train_1[index]\n","    X_leave = X_train[leave_index]\n","\n","    Y_add = Y_train_1[index]\n","    Y_leave = Y_train[leave_index]\n","\n","    X_train[leave_index] = X_add\n","    X_train.append(X_leave)\n","\n","    Y_train[leave_index] = Y_add\n","    Y_train.append(Y_leave)\n","\n","\n","  X_train = np.array(X_train)\n","  Y_train = np.array(Y_train)\n","  return X_train,Y_train\n","\n","audio_train = np.nan_to_num(audio_train)\n","text_train = np.nan_to_num(text_train)\n","\n","audio_train, _ = upsample(audio_train,Ytrain)\n","text_train, Ytrain = upsample(text_train,Ytrain)\n","\n","print(audio_train.shape)\n","print(text_train.shape)\n","print(Ytrain.shape)\n","\n","for i in range(audio_train.shape[0]):\n","  audio_train[i] = sklearn.preprocessing.normalize(audio_train[i])\n","  text_train[i] = sklearn.preprocessing.normalize(text_train[i])\n","\n","\n","print(Ytest.shape)\n","\n","\n","\n","audio_test = np.nan_to_num(audio_test)\n","text_test = np.nan_to_num(text_test)\n","\n","\n","for i in range(audio_test.shape[0]):\n","  audio_test[i] = sklearn.preprocessing.normalize(audio_test[i])\n","  text_test[i] = sklearn.preprocessing.normalize(text_test[i])"],"execution_count":27,"outputs":[{"output_type":"stream","text":["(16, 250, 74) (16, 250, 5100)\n","(50, 250, 74) (50, 250, 5100)\n","(88, 250, 74)\n","(88, 250, 5100)\n","(88,)\n","(16,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jmzQRMUCYyK5","executionInfo":{"status":"ok","timestamp":1627106784909,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sri Vishnuvardhan Reddy Akepati","photoUrl":"","userId":"12972633878670662839"}}},"source":["def Thresholding(Y_pred, threshold):\n","  Y_pred2 = []\n","  print(\"Y_pred: \", Y_pred.shape)\n","  for i in range(len(Y_pred)):\n","    if(Y_pred[i] < threshold):\n","      Y_pred2.append(0)\n","    else:\n","      Y_pred2.append(1)\n","\n","  return np.array(Y_pred2)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EhbzFk7bY2tQ","executionInfo":{"status":"ok","timestamp":1627106987657,"user_tz":-330,"elapsed":202762,"user":{"displayName":"Sri Vishnuvardhan Reddy Akepati","photoUrl":"","userId":"12972633878670662839"}},"outputId":"631a8092-234f-4872-8066-6201dad81bf0"},"source":["print(\"-------------------------------------- TEXT (W/o GATING) SENTENCE LEVEL-------------------------------------------------\")\n","input3 = Input(shape = (250,5100))\n","dense4 = Dense(1000)(input3)\n","dense5 = Dense(500)(dense4)\n","dense6 = Dense(250)(dense5)\n","# interpretation model\n","lstm = LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)(dense6)\n","output = Dense(1, activation='sigmoid')(lstm)\n","model = Model(inputs=input3, outputs=output)\n","# summarize layers\n","# print(model.summary())\n","# plot graph\n","# print(plot_model(model, to_file='multiple_inputs.png'))\n","optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001)\n","model.compile(optimizer=optimizer, loss='binary_crossentropy')   \n","\n","\n","model.fit(text_train,Ytrain, epochs=50,validation_split = 0.2, callbacks = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss', min_delta=0, patience=20, verbose=0, mode='min',\n","    baseline=None, restore_best_weights=True), batch_size = 137)\n","\n","\n","\n","\n","from sklearn.metrics import classification_report\n","pred = model.predict(text_test)\n","\n","print(classification_report(Ytest,Thresholding(pred,0.5)))\n","# print(classification_report(Ytest,Thresholding(pred,0.6)))\n","# print(classification_report(Ytest,Thresholding(pred,0.4)))\n","# print(classification_report(Ytest,Thresholding(pred,0.3)))\n","# print(classification_report(Ytest,Thresholding(pred,0.7)))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["-------------------------------------- TEXT (W/o GATING) SENTENCE LEVEL-------------------------------------------------\n","Epoch 1/50\n","1/1 [==============================] - 7s 7s/step - loss: 0.6920 - val_loss: 0.6846\n","Epoch 2/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.6800 - val_loss: 0.6771\n","Epoch 3/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.6677 - val_loss: 0.6695\n","Epoch 4/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.6557 - val_loss: 0.6615\n","Epoch 5/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.6436 - val_loss: 0.6529\n","Epoch 6/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.6310 - val_loss: 0.6436\n","Epoch 7/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.6179 - val_loss: 0.6338\n","Epoch 8/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.6058 - val_loss: 0.6236\n","Epoch 9/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.5930 - val_loss: 0.6131\n","Epoch 10/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.5798 - val_loss: 0.6023\n","Epoch 11/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.5647 - val_loss: 0.5915\n","Epoch 12/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.5504 - val_loss: 0.5807\n","Epoch 13/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.5377 - val_loss: 0.5698\n","Epoch 14/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.5238 - val_loss: 0.5589\n","Epoch 15/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.5092 - val_loss: 0.5478\n","Epoch 16/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.4961 - val_loss: 0.5363\n","Epoch 17/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.4814 - val_loss: 0.5240\n","Epoch 18/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.4656 - val_loss: 0.5106\n","Epoch 19/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.4481 - val_loss: 0.4960\n","Epoch 20/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.4298 - val_loss: 0.4800\n","Epoch 21/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.4093 - val_loss: 0.4625\n","Epoch 22/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.3869 - val_loss: 0.4435\n","Epoch 23/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.3650 - val_loss: 0.4230\n","Epoch 24/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.3422 - val_loss: 0.4013\n","Epoch 25/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.3175 - val_loss: 0.3786\n","Epoch 26/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.2957 - val_loss: 0.3554\n","Epoch 27/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.2727 - val_loss: 0.3320\n","Epoch 28/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.2533 - val_loss: 0.3086\n","Epoch 29/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.2335 - val_loss: 0.2856\n","Epoch 30/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.2123 - val_loss: 0.2631\n","Epoch 31/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.1943 - val_loss: 0.2410\n","Epoch 32/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.1766 - val_loss: 0.2196\n","Epoch 33/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.1608 - val_loss: 0.1992\n","Epoch 34/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.1429 - val_loss: 0.1800\n","Epoch 35/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.1282 - val_loss: 0.1624\n","Epoch 36/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.1124 - val_loss: 0.1466\n","Epoch 37/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0989 - val_loss: 0.1326\n","Epoch 38/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0873 - val_loss: 0.1201\n","Epoch 39/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0769 - val_loss: 0.1090\n","Epoch 40/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0672 - val_loss: 0.0989\n","Epoch 41/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0603 - val_loss: 0.0895\n","Epoch 42/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0528 - val_loss: 0.0808\n","Epoch 43/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0469 - val_loss: 0.0726\n","Epoch 44/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0422 - val_loss: 0.0649\n","Epoch 45/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0372 - val_loss: 0.0578\n","Epoch 46/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0325 - val_loss: 0.0513\n","Epoch 47/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0293 - val_loss: 0.0455\n","Epoch 48/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0258 - val_loss: 0.0403\n","Epoch 49/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0229 - val_loss: 0.0358\n","Epoch 50/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.0206 - val_loss: 0.0319\n","Y_pred:  (16, 1)\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.77      0.77        13\n","           1       0.00      0.00      0.00         3\n","\n","    accuracy                           0.62        16\n","   macro avg       0.38      0.38      0.38        16\n","weighted avg       0.62      0.62      0.62        16\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F3zvKtQ3MjoX","executionInfo":{"status":"ok","timestamp":1627108431648,"user_tz":-330,"elapsed":15089,"user":{"displayName":"Sri Vishnuvardhan Reddy Akepati","photoUrl":"","userId":"12972633878670662839"}},"outputId":"f0db38e1-e2b7-475b-a088-dccab24c2001"},"source":["print(\"--------------------------------------AUDIO (W/o GATING) SENTENCE LEVEL-------------------------------------------------\")\n","input3 = Input(shape = (250,74))\n","# dense4 = Dense(1000)(input3)\n","# dense5 = Dense(500)(dense4)\n","# dense6 = Dense(250)(dense5)\n","# interpretation model\n","lstm = LSTM(60, dropout = 0.2, recurrent_dropout = 0.2)(input3)\n","output = Dense(1, activation='sigmoid')(lstm)\n","model = Model(inputs=input3, outputs=output)\n","  # summarize layers\n","  # print(model.summary())\n","  # plot graph\n","  # print(plot_model(model, to_file='multiple_inputs.png'))\n","optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0001)\n","model.compile(optimizer=optimizer, loss='binary_crossentropy')\n","\n","model.fit(audio_train,Ytrain, validation_split = 0.2, callbacks = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss', min_delta=0, patience=30, verbose=0, mode='min',\n","    baseline=None, restore_best_weights=True), epochs=50, batch_size = 137)\n","\n","pred = model.predict(audio_test)\n","\n","print(classification_report(Ytest,Thresholding(pred,0.8)))\n","# print(classification_report(Ytest,Thresholding(pred,0.6)))\n","# print(classification_report(Ytest,Thresholding(pred,0.4)))\n","# print(classification_report(Ytest,Thresholding(pred,0.3)))\n","# print(classification_report(Ytest,Thresholding(pred,0.7)))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["--------------------------------------AUDIO (W/o GATING) SENTENCE LEVEL-------------------------------------------------\n","Epoch 1/50\n","1/1 [==============================] - 3s 3s/step - loss: 0.6938 - val_loss: 0.6901\n","Epoch 2/50\n","1/1 [==============================] - 0s 358ms/step - loss: 0.6956 - val_loss: 0.6914\n","Epoch 3/50\n","1/1 [==============================] - 0s 370ms/step - loss: 0.6933 - val_loss: 0.6926\n","Epoch 4/50\n","1/1 [==============================] - 0s 356ms/step - loss: 0.6935 - val_loss: 0.6939\n","Epoch 5/50\n","1/1 [==============================] - 0s 353ms/step - loss: 0.6921 - val_loss: 0.6951\n","Epoch 6/50\n","1/1 [==============================] - 0s 374ms/step - loss: 0.6923 - val_loss: 0.6963\n","Epoch 7/50\n","1/1 [==============================] - 0s 355ms/step - loss: 0.6922 - val_loss: 0.6975\n","Epoch 8/50\n","1/1 [==============================] - 0s 373ms/step - loss: 0.6920 - val_loss: 0.6987\n","Epoch 9/50\n","1/1 [==============================] - 0s 353ms/step - loss: 0.6916 - val_loss: 0.7000\n","Epoch 10/50\n","1/1 [==============================] - 0s 365ms/step - loss: 0.6916 - val_loss: 0.7012\n","Epoch 11/50\n","1/1 [==============================] - 0s 370ms/step - loss: 0.6911 - val_loss: 0.7024\n","Epoch 12/50\n","1/1 [==============================] - 0s 361ms/step - loss: 0.6918 - val_loss: 0.7036\n","Epoch 13/50\n","1/1 [==============================] - 0s 351ms/step - loss: 0.6898 - val_loss: 0.7048\n","Epoch 14/50\n","1/1 [==============================] - 0s 354ms/step - loss: 0.6890 - val_loss: 0.7060\n","Epoch 15/50\n","1/1 [==============================] - 0s 374ms/step - loss: 0.6897 - val_loss: 0.7072\n","Epoch 16/50\n","1/1 [==============================] - 0s 358ms/step - loss: 0.6900 - val_loss: 0.7084\n","Epoch 17/50\n","1/1 [==============================] - 0s 365ms/step - loss: 0.6901 - val_loss: 0.7096\n","Epoch 18/50\n","1/1 [==============================] - 0s 382ms/step - loss: 0.6899 - val_loss: 0.7108\n","Epoch 19/50\n","1/1 [==============================] - 0s 362ms/step - loss: 0.6883 - val_loss: 0.7120\n","Epoch 20/50\n","1/1 [==============================] - 0s 355ms/step - loss: 0.6869 - val_loss: 0.7131\n","Epoch 21/50\n","1/1 [==============================] - 0s 361ms/step - loss: 0.6898 - val_loss: 0.7143\n","Epoch 22/50\n","1/1 [==============================] - 0s 371ms/step - loss: 0.6871 - val_loss: 0.7155\n","Epoch 23/50\n","1/1 [==============================] - 0s 368ms/step - loss: 0.6898 - val_loss: 0.7166\n","Epoch 24/50\n","1/1 [==============================] - 0s 369ms/step - loss: 0.6902 - val_loss: 0.7177\n","Epoch 25/50\n","1/1 [==============================] - 0s 380ms/step - loss: 0.6892 - val_loss: 0.7187\n","Epoch 26/50\n","1/1 [==============================] - 0s 377ms/step - loss: 0.6888 - val_loss: 0.7198\n","Epoch 27/50\n","1/1 [==============================] - 0s 372ms/step - loss: 0.6887 - val_loss: 0.7208\n","Epoch 28/50\n","1/1 [==============================] - 0s 361ms/step - loss: 0.6876 - val_loss: 0.7218\n","Epoch 29/50\n","1/1 [==============================] - 0s 369ms/step - loss: 0.6890 - val_loss: 0.7228\n","Epoch 30/50\n","1/1 [==============================] - 0s 359ms/step - loss: 0.6880 - val_loss: 0.7238\n","Epoch 31/50\n","1/1 [==============================] - 0s 351ms/step - loss: 0.6873 - val_loss: 0.7247\n","WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f27d8ac7170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Y_pred:  (16, 1)\n","              precision    recall  f1-score   support\n","\n","           0       0.81      1.00      0.90        13\n","           1       0.00      0.00      0.00         3\n","\n","    accuracy                           0.81        16\n","   macro avg       0.41      0.50      0.45        16\n","weighted avg       0.66      0.81      0.73        16\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zn-UKEYsAsQh","executionInfo":{"status":"ok","timestamp":1627108597424,"user_tz":-330,"elapsed":75096,"user":{"displayName":"Sri Vishnuvardhan Reddy Akepati","photoUrl":"","userId":"12972633878670662839"}},"outputId":"9a483254-75e7-40e3-a5db-706f685054e4"},"source":["print(\"--------------------------------------AUDIO + TEXT (W GATING) SENTENCE LEVEL-------------------------------------------------\")\n","model1 = text_audio()\n","model = model1.run_model()\n","\n","model.fit([audio_train,text_train],Ytrain, validation_split = 0.2, callbacks = tf.keras.callbacks.EarlyStopping(\n","        monitor='val_loss', min_delta=0, patience=15, verbose=0, mode='min',\n","        baseline=None, restore_best_weights=True),epochs=50, batch_size = 137)\n","\n","\n","from sklearn.metrics import classification_report\n","pred = model.predict([audio_test,text_test])\n","pred2 = model.predict([audio_train,text_train])\n","\n","print(classification_report(Ytest,Thresholding(pred,0.7)))\n","# print(classification_report(Ytest,Thresholding(pred,0.6)))\n","# print(classification_report(Ytest,Thresholding(pred,0.4)))\n","# print(classification_report(Ytest,Thresholding(pred,0.3)))\n","# print(classification_report(Ytest,Thresholding(pred,0.7)))"],"execution_count":38,"outputs":[{"output_type":"stream","text":["--------------------------------------AUDIO + TEXT (W GATING) SENTENCE LEVEL-------------------------------------------------\n","Epoch 1/50\n","1/1 [==============================] - 10s 10s/step - loss: 0.0029 - val_loss: 0.0103\n","Epoch 2/50\n","1/1 [==============================] - 6s 6s/step - loss: 0.0028 - val_loss: 0.0104\n","Epoch 3/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0028 - val_loss: 0.0104\n","Epoch 4/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0028 - val_loss: 0.0104\n","Epoch 5/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0027 - val_loss: 0.0104\n","Epoch 6/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0027 - val_loss: 0.0105\n","Epoch 7/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0027 - val_loss: 0.0105\n","Epoch 8/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0027 - val_loss: 0.0105\n","Epoch 9/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0025 - val_loss: 0.0105\n","Epoch 10/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0026 - val_loss: 0.0106\n","Epoch 11/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0025 - val_loss: 0.0106\n","Epoch 12/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0024 - val_loss: 0.0106\n","Epoch 13/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0024 - val_loss: 0.0106\n","Epoch 14/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0023 - val_loss: 0.0107\n","Epoch 15/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0024 - val_loss: 0.0107\n","Epoch 16/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.0023 - val_loss: 0.0108\n","Y_pred:  (16, 1)\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.77      0.77        13\n","           1       0.00      0.00      0.00         3\n","\n","    accuracy                           0.62        16\n","   macro avg       0.38      0.38      0.38        16\n","weighted avg       0.62      0.62      0.62        16\n","\n"],"name":"stdout"}]}]}